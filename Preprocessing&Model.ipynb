{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzHOL40BIb9MdVdhNFp7cs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install sentence_transformers"],"metadata":{"id":"eyFDagOC7bbV","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":8534,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee29d1b8-246d-4f54-a20a-4d7fed3777f1"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.6.1)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.99)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","import nltk.data\n","import nltk\n","import json\n","import csv\n","from transformers import pipeline# sửa lỗi chính tả\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sentence_transformers import SentenceTransformer # embedding câu\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import random\n","import torch.optim.lr_scheduler as lr_scheduler"],"metadata":{"id":"gHciWNYwWYJT","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":15,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-aITJ7s1OPG1","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":15,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"7a02e0d6-0988-416c-b3bd-0d5ad2b904e3"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["\n","# Mô hình tokennizer sentence và sửa lỗi chính tả, embedding câu.\n","nltk.download('punkt')\n","class Panthera:\n","  def __init__(self):\n","    tokenizer = nltk.data.load('tokenizers/punkt/PY3/english.pickle')\n","    fix_spelling = pipeline(\"text2text-generation\",model=\"oliverguhr/spelling-correction-english-base\")\n","    # fix_spelling= pipeline(\n","    #           'text2text-generation',\n","    #           'pszemraj/flan-t5-large-grammar-synthesis',\n","    #           )\n","    self.tokenize = tokenizer.tokenize\n","    self.fix_spelling = fix_spelling\n","\n","  @staticmethod\n","  def flatten(lst):\n","    flat_list = []\n","    for item in lst:\n","        if isinstance(item, list):\n","            flat_list.extend(Panthera.flatten(item))\n","        else:\n","            flat_list.append(item)\n","    return flat_list\n","\n","  def execute(self,text, max_depth = 5, check_spelling = True):#1 đoạn văn bản\n","    # lặp lại cho đến khi không còn sự thay đổi nào\n","    list_tokens_sent = self.tokenize(text)\n","\n","    if check_spelling:\n","      deep = 0\n","      while(True):\n","        for i in range(len(list_tokens_sent)):#duyệt list các token sent đã được chia tách, kiểm tra chính tả và sửa\n","          list_tokens_sent[i] = self.fix_spelling(list_tokens_sent[i], max_length = 2048)[0]['generated_text'] #, max_length = 2048\n","\n","\n","        # tiếp tục phân tách cho đến khi không thay đổi\n","        pre_len = len(list_tokens_sent)\n","        for i in range(len(list_tokens_sent)):\n","          list_tokens_sent[i] = self.tokenize(list_tokens_sent[i])\n","\n","        # dãn list_tokens_sent thành 1 mảng chứa các token duy nhất\n","        list_tokens_sent = Panthera.flatten(list_tokens_sent)\n","        # kiểm tra thay đổi\n","        deep += 1\n","        if pre_len == len(list_tokens_sent) or deep == max_depth:\n","          break\n","\n","    return list_tokens_sent\n","  @staticmethod\n","  def text2embedding(sentence):\n","    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n","    # Sentences are encoded by calling model.encode()\n","    embedding = model.encode(sentence)\n","\n","    return torch.Tensor(embedding) if len(embedding.shape) >= 2 else torch.Tensor([embedding])"]},{"cell_type":"code","source":["# Tiền xử lí: thực hiện Panthera và ghi lại\n","class Rabbit:\n","  def __init__(self) -> None:\n","    self.call_function = False\n","    pass\n","  def get_file(self,function = None):\n","    # thực hiện các thao tác tạo file, lấy file,...\n","    if self.call_function:\n","      return \"already\"\n","\n","    self.call_function = True\n","\n","    if function == None:\n","      drive.mount('/content/drive')\n","      file_path = '/content/drive/My Drive/data_mining_project/Data-for-Data-Mining-Project - Source.csv'\n","\n","      file_path_save = '/content/drive/My Drive/data_mining_project/Comment_Sentiment.csv'\n","      # pd.DataFrame(columns = ['ID','Tokenize Sentence', 'Label']).to_csv(file_path_save, header=True, index=False, mode = 'w')\n","\n","      children_leopard = Panthera()\n","\n","      df = pd.read_csv(file_path)\n","\n","      header = True\n","\n","      for i in range(df.shape[0]):\n","        sub_df = df.iloc[[i]]\n","        text = sub_df['Review Title'] + '. ' + sub_df['Review Content']\n","        text = text.values[0]\n","        data = {'ID':i,'Tokenize Sentence':children_leopard.execute(text), 'Label':sub_df['Label'].values[0]}\n","        print(data)\n","\n","        # Lưu từ điển vào tệp CSV\n","        file_path = file_path_save\n","        my_dict = data\n","        with open(file_path, 'a', newline='') as csvfile:\n","            fieldnames = my_dict.keys()\n","            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","            if header:\n","              writer.writeheader()\n","              header = False\n","            writer.writerow(my_dict)\n","\n","    else:\n","       return function"],"metadata":{"id":"nJIBPyQKykJS","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":14,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# children_rabbit = Rabbit()\n","# children_rabbit.get_file()\n","\n","# đã ghi"],"metadata":{"id":"Cos9EQ6b3B0m","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":14,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["class Data(Dataset):#dữ liệu phải có dạng: một cột là các comment, mỗi comment đã được phân tách thành list các câu, cột còn lại là sentiment positive, negative\n","  def __init__(self, data, target):\n","        self.data = data\n","        self.target = target\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, index):\n","    # print(index)\n","    x = self.data[index]\n","    y = self.target[index]\n","    return x, y\n","\n","class PrepareData():\n","  '''\n","  Đầu vào vẫn là các list thông thường\n","  '''\n","  def __init__(self, data, target) -> None:\n","    dataset = Data(data, target)\n","\n","    self.trainset, self.validationset, self.testset = random_split(dataset, [0.8, 0.1, 0.1])\n","\n","  @staticmethod\n","  def collate_fn(batch):\n","    # Sắp xếp các mẫu trong batch theo độ dài chuỗi giảm dần\n","    batch.sort(key=lambda x: len(x[0]), reverse=True)\n","\n","\n","    # batch = [(data1, label1), (data2, label2), ...].Bằng cách sử dụng zip(*batch), chúng ta thực hiện unpack các thành phần của batch theo chiều dọc\n","\n","    # Tách dữ liệu và nhãn từ các mẫu\n","    data, labels = zip(*batch)\n","    labels = torch.Tensor(labels)\n","\n","    # Tạo batch tensor bằng cách padding các sequence trong list\n","    padded_sequences = nn.utils.rnn.pad_sequence(data, batch_first=True)\n","\n","    # Đếm độ dài thực tế của mỗi sequence trong batch\n","    sequence_lengths = [len(seq) for seq in data]\n","\n","\n","    # Chuyển đổi batch tensor thành PackedSequence\n","    packed_sequence = torch.nn.utils.rnn.pack_padded_sequence(padded_sequences, sequence_lengths, batch_first=True)\n","\n","    return packed_sequence, labels\n","\n","  def getData(self, batch_size, download = True):\n","    if download:\n","      path_train_loader = '/content/drive/My Drive/data_mining_project/train_loader.pkl'\n","      path_validation_loader = '/content/drive/My Drive/data_mining_project/validation_loader.pkl'\n","      path_test_loader = '/content/drive/My Drive/data_mining_project/test_loader.pkl'\n","\n","      with open(path_train_loader, 'rb') as f:\n","        train_loader = pickle.load(f)\n","\n","      with open(path_validation_loader, 'rb') as f:\n","        validation_loader = pickle.load(f)\n","\n","      with open(path_test_loader, 'rb') as f:\n","        test_loader = pickle.load(f)\n","\n","\n","      train_loader = torch.utils.data.DataLoader(train_loader.dataset, batch_size=batch_size,\n","                                                  shuffle=True,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","      validation_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size,\n","                                                  shuffle=False,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","      test_loader = torch.utils.data.DataLoader(self.validationset, batch_size=batch_size,\n","                                                shuffle=False,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","\n","      return train_loader, validation_loader, test_loader\n","\n","\n","    else:\n","      train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size,\n","                                                  shuffle=True,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","      validation_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size,\n","                                                  shuffle=False,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","      test_loader = torch.utils.data.DataLoader(self.validationset, batch_size=batch_size,\n","                                                shuffle=False,collate_fn=PrepareData.collate_fn, num_workers=0, pin_memory=False)\n","\n","      return train_loader, validation_loader, test_loader\n"],"metadata":{"id":"iy0ErjecYZBZ","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":14,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Mô hình LSTM, trước hết biến đổi 1 câu thành embedding\n","\n","# Xây dựng lớp mô hình LSTM\n","class LSTMModel(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, output_dim, dropout = 0.2, numlayers = 1, bidirectional = False):\n","        super(LSTMModel, self).__init__()\n","        self.num_layers = numlayers\n","        self.D = 2 if bidirectional else 1\n","\n","        self.hidden_dim = hidden_dim # có giá trị tự do\n","        self.embedding_dim = embedding_dim # chiều của embedding, vd: [1,2,3,...300]: 1 embedding có kích thước là 300\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim,batch_first=True, num_layers = numlayers, dropout = dropout, bidirectional=bidirectional) # đầu vào của LSTM là có kích thước embedding và đầu ra có kích thước hidden, xây dựng 1 mô hình LSTM\n","        # input_size = embedding_dim; hidden_size, num_layer\n","        # tuning ở ngay trên\n","        self.fc = nn.Linear(self.D*hidden_dim, output_dim) # 1 fully conected để làm đầu ra\n","\n","\n","\n","    def forward(self, inputs):\n","\n","        '''\n","        đầu vào input lần lượt là: batch_size, sequence_length, embedding_dim\n","        '''\n","        # inputs = torch.nn.utils.rnn.pack_padded_sequence(inputs, )\n","\n","        batch_size = inputs.batch_sizes[0].item()#input ở đây chính là 1 batch mà chúng ta cho vào, và tập huấn luyện của chúng ta chứa những inputs này\n","        hidden = self.init_hidden(batch_size)\n","        lstm_out, _ = self.lstm(inputs, hidden)\n","\n","        # Giải nén lstm_out\n","        padded_outputs, _ = pad_packed_sequence(lstm_out, batch_first=True)\n","\n","\n","        padded_outputs = padded_outputs[:, -1, :]\n","\n","        output = self.fc(padded_outputs)\n","        return output\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(self.D * self.num_layers, batch_size, self.hidden_dim),# gồm 1 phần chứa batch_size 'phần', 'phần' chứa hidden_dim units\n","                torch.zeros(self.D * self.num_layers, batch_size, self.hidden_dim))\n","\n","\n","class Tiger:#huấn luyện và predict\n","  def __init__(self, data, target, model = None,hidden_dim = 128, dropout = 0.0, numlayers = 1, bidirectional = False, batch_size = 4, lr = 0.01, gammar = 0.1):\n","    if model == None:\n","      embedding_dim = 384\n","\n","      output_dim = 1\n","      model = LSTMModel(embedding_dim, hidden_dim, output_dim, dropout=dropout, numlayers = numlayers, bidirectional = bidirectional)\n","      self.model = model\n","    else:\n","      self.model = model\n","\n","    preparedata = PrepareData(data, labels)\n","    self.train_loader ,self.validation_loader,self.test_loader = preparedata.getData(batch_size)\n","\n","    self.max_sequence_length = 128\n","\n","    self.lr = lr\n","\n","    self.gammar = gammar\n","\n","    pass\n","  def get_train_valid_test(self):\n","    return self.train_loader ,self.validation_loader, self.test_loader\n","\n","  def train(self, earlystop_train = False):\n","    # Khởi tạo mô hình\n","\n","    # Định nghĩa hàm mất mát và bộ tối ưu hóa\n","    criterion = nn.BCEWithLogitsLoss()# kết hợp giữa sigmoid và BCE\n","    optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n","    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=self.gammar)\n","    # Huấn luyện mô hình\n","    all_train_loss = []\n","    all_validation_loss = []\n","    all_accuracy = []\n","\n","    best_loss = float('inf')\n","    early_stop_counter = 0\n","    patience = 5\n","\n","    for epoch in range(50):\n","      self.model.train()\n","      # self.train_loader.shuffle()\n","\n","      train_loss = 0\n","\n","      for inputs, labels in self.train_loader:\n","          optimizer.zero_grad()\n","          outputs = self.model(inputs)\n","\n","          loss = criterion(outputs.squeeze(), labels)\n","          train_loss += loss.item() * inputs.batch_sizes[0]\n","\n","          loss.backward()\n","          optimizer.step()\n","\n","      train_loss /= len(self.train_loader.dataset)\n","      all_train_loss.append(train_loss)\n","      # Bước giảm learning rate\n","      scheduler.step()\n","\n","      self.model.eval()\n","      with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        validation_loss = 0\n","        for inputs, labels in self.validation_loader:\n","            outputs = self.model(inputs).squeeze()\n","            loss = criterion(outputs, labels)\n","            validation_loss += loss.item() * inputs.batch_sizes[0]\n","\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","\n","            total += labels.size(0)\n","\n","            correct += (predicted_labels == labels.float()).sum().item()\n","\n","        accuracy = correct / total\n","        validation_loss /= len(self.validation_loader.dataset)\n","\n","        all_validation_loss.append(validation_loss)\n","        all_accuracy.append(accuracy)\n","\n","        if earlystop_train:\n","          if train_loss < best_loss:\n","              best_loss = train_loss\n","              early_stop_counter = 0\n","          else:\n","              early_stop_counter += 1\n","              if early_stop_counter >= patience:\n","                  break\n","        else:\n","          if validation_loss < best_loss:\n","              best_loss = validation_loss\n","              early_stop_counter = 0\n","          else:\n","              early_stop_counter += 1\n","              if early_stop_counter >= patience:\n","                  break\n","\n","    return all_train_loss, all_validation_loss, all_accuracy\n","\n","\n","\n","  def test(self):\n","    # Đánh giá mô hình trên dữ liệu kiểm tra\n","    self.model.eval()\n","    with torch.no_grad():\n","        correct = 0\n","        total = 0\n","        for inputs, labels in self.test_loader:\n","            outputs = self.model(inputs).squeeze()\n","\n","            predicted_labels = (torch.sigmoid(outputs) > 0.5).float()\n","\n","            total += labels.size(0)\n","\n","            correct += (predicted_labels == labels.float()).sum().item()\n","\n","        accuracy = correct / total\n","    return accuracy\n","\n","  def predict(self,text, check_spelling = False):# một đoạn hoàn chỉnh\n","    # chuyển về tokenizton sentence\n","    panthera = Panthera()\n","    tokens = panthera.execute(text, check_spelling)\n","\n","    if len(tokens) > self.max_sequence_length:\n","      indices = random.sample(range(len(tokens)), self.max_sequence_length)\n","      indices.sort()\n","      tokens = [tokens[i] for i in indices]\n","\n","    new_data = Panthera.text2embedding(tokens)\n","    new_data = new_data.unsqueeze(0)\n","\n","    sequence_lengths = [len(seq) for seq in new_data]\n","\n","    new_data = pack_padded_sequence(new_data, sequence_lengths, batch_first=True)\n","\n","    # print(new_data.size())\n","\n","    self.model.eval()\n","    with torch.no_grad():\n","        inputs = new_data\n","        outputs = self.model(inputs)#gọi hàm forward\n","\n","        proba_label = torch.sigmoid(outputs)\n","        predict_label = (torch.sigmoid(outputs) > 0.5).float()\n","\n","\n","    return proba_label, 'positive' if predict_label == 1 else 'negative'"],"metadata":{"id":"ytec5iTUZx68","executionInfo":{"status":"ok","timestamp":1711652808054,"user_tz":-420,"elapsed":14,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')\n","\n","path = '/content/drive/My Drive/data_mining_project/Comment_Sentiment.csv'\n","path_save = '/content/drive/My Drive/data_mining_project/Sub_Embedding.csv'\n","df = pd.read_csv(path)\n","\n","df['Tokenize Sentence'] = df['Tokenize Sentence'].apply(lambda x: eval(x))\n","length = [len(cell) for cell in df['Tokenize Sentence']]\n","max_length = max(length)\n","min_length = min(length)\n","mean_length = np.mean(length)\n","print(f\"max_length {max_length} \\n min_length {min_length} \\n {mean_length}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NrKqQkvDHuo8","executionInfo":{"status":"ok","timestamp":1711652810565,"user_tz":-420,"elapsed":2524,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"1a70e674-9dad-4219-f3b7-086dc83b32af"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","max_length 51 \n"," min_length 1 \n"," 5.643643643643643\n"]}]},{"cell_type":"code","source":["MAX_SEQUENCE_LENGTH = 128"],"metadata":{"id":"9P-IQ_4QYvwu","executionInfo":{"status":"ok","timestamp":1711652810565,"user_tz":-420,"elapsed":4,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["df_head_20 = df\n","\n","# df_head_20['Tokenize Sentence'] = df_head_20['Tokenize Sentence'].apply(lambda x: eval(x))\n","\n","data = [Panthera.text2embedding(df_head_20['Tokenize Sentence'].iloc[i]) for i in df_head_20.index]\n","labels = [0 if label == 'Negative' else 1 for label in df_head_20['Label']]\n"],"metadata":{"id":"3SNkc8stXUYt","executionInfo":{"status":"ok","timestamp":1711653377199,"user_tz":-420,"elapsed":566637,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["# tiger = Tiger(data, labels)\n","\n","# print(tiger.train(earlystop_train = True))\n","# print(tiger.test())\n","# tiger.predict(\"I love this\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"23nKT9pZQRqQ","executionInfo":{"status":"ok","timestamp":1711653408090,"user_tz":-420,"elapsed":30904,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"22cf7ff3-ae0e-4eb1-94d5-6e4ee7ad70c3"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["([tensor(0.6188), tensor(0.5419), tensor(0.5163), tensor(0.5268), tensor(0.5248), tensor(0.5187), tensor(0.5093), tensor(0.5181), tensor(0.5279), tensor(0.5253), tensor(0.5114), tensor(0.5145)], [tensor(0.5353), tensor(0.5491), tensor(0.5418), tensor(0.5412), tensor(0.5411), tensor(0.5411), tensor(0.5411), tensor(0.5411), tensor(0.5411), tensor(0.5411), tensor(0.5411), tensor(0.5411)], [0.71, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7])\n","0.696969696969697\n"]},{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["# tunning hyperparameter\n","\n","import optuna\n","\n","def objective(trial):\n","  # hidden_dim = 128, dropout = 0.0, numlayers = 1, bidirectional = False, batch_size = 4, lr = 0.01, gammar = 0.1\n","  hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256])\n","  dropout = trial.suggest_float('dropout', 0, 0.5)\n","  num_layers = trial.suggest_int('num_layers', 1, 4)\n","  bidirectional = trial.suggest_categorical('bidirectional', [True, False])\n","  batch_size = trial.suggest_categorical('batch_size', [2, 4, 8, 16])\n","  lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n","  gammar = trial.suggest_loguniform('gammar', 1e-3, 1e-1)\n","\n","  tiger = Tiger(data, labels, model = None,hidden_dim = hidden_dim, dropout = dropout, numlayers = num_layers,\n","                bidirectional = bidirectional, batch_size = batch_size, lr = lr, gammar = gammar)\n","  _, target_value,_ = tiger.train()\n","  target_value = target_value[-1].item()\n","  return target_value\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=100)\n","\n","# Truy cập vào giá trị tốt nhất và siêu tham số tương ứng\n","best_params = study.best_params\n","best_value = study.best_value\n","\n","print('Best Parameters:', best_params)\n","print('Best Value:', best_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b70UL810A86A","executionInfo":{"status":"ok","timestamp":1711658692064,"user_tz":-420,"elapsed":5283979,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"818542fe-aaa4-4647-eb69-ffe0d877ae05"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2024-03-28 19:16:46,710] A new study created in memory with name: no-name-a6475b85-8f3b-40ac-8b4b-a2f874d41911\n","<ipython-input-53-47858bf4fbe8>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  lr = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n","<ipython-input-53-47858bf4fbe8>:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  gammar = trial.suggest_loguniform('gammar', 1e-3, 1e-1)\n","[I 2024-03-28 19:17:32,770] Trial 0 finished with value: 0.6938409209251404 and parameters: {'hidden_dim': 256, 'dropout': 0.19284345863427543, 'num_layers': 2, 'bidirectional': True, 'batch_size': 16, 'learning_rate': 1.4303570548574057e-05, 'gammar': 0.001474288995543751}. Best is trial 0 with value: 0.6938409209251404.\n","[I 2024-03-28 19:18:10,877] Trial 1 finished with value: 0.690896213054657 and parameters: {'hidden_dim': 64, 'dropout': 0.3391849801262693, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 1.8344041667668626e-05, 'gammar': 0.0344067093274893}. Best is trial 1 with value: 0.690896213054657.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.0309708154682658 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:18:42,598] Trial 2 finished with value: 0.5583477020263672 and parameters: {'hidden_dim': 256, 'dropout': 0.0309708154682658, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.00121322279749279, 'gammar': 0.004002720853250636}. Best is trial 2 with value: 0.5583477020263672.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4643621523726149 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:19:27,227] Trial 3 finished with value: 0.4764207899570465 and parameters: {'hidden_dim': 256, 'dropout': 0.4643621523726149, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00017686285814703674, 'gammar': 0.002358281966153}. Best is trial 3 with value: 0.4764207899570465.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.12543728800064807 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:19:37,004] Trial 4 finished with value: 0.6283703446388245 and parameters: {'hidden_dim': 64, 'dropout': 0.12543728800064807, 'num_layers': 1, 'bidirectional': False, 'batch_size': 8, 'learning_rate': 0.007687638043927602, 'gammar': 0.007976265640738365}. Best is trial 3 with value: 0.4764207899570465.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22562877091381423 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:19:53,633] Trial 5 finished with value: 0.671139657497406 and parameters: {'hidden_dim': 64, 'dropout': 0.22562877091381423, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.00011121413487091802, 'gammar': 0.0891770989006796}. Best is trial 3 with value: 0.4764207899570465.\n","[I 2024-03-28 19:21:46,494] Trial 6 finished with value: 0.6700695157051086 and parameters: {'hidden_dim': 64, 'dropout': 0.21215093308224442, 'num_layers': 4, 'bidirectional': True, 'batch_size': 2, 'learning_rate': 0.0075855393548700635, 'gammar': 0.0010096212724667274}. Best is trial 3 with value: 0.4764207899570465.\n","[I 2024-03-28 19:23:45,372] Trial 7 finished with value: 0.6115689873695374 and parameters: {'hidden_dim': 128, 'dropout': 0.1563292169619463, 'num_layers': 4, 'bidirectional': True, 'batch_size': 4, 'learning_rate': 0.00019025107578553465, 'gammar': 0.03738941147727116}. Best is trial 3 with value: 0.4764207899570465.\n","[I 2024-03-28 19:24:32,925] Trial 8 finished with value: 0.6877556443214417 and parameters: {'hidden_dim': 256, 'dropout': 0.25836864650339325, 'num_layers': 3, 'bidirectional': False, 'batch_size': 8, 'learning_rate': 1.5198149940398882e-05, 'gammar': 0.0013555807670920478}. Best is trial 3 with value: 0.4764207899570465.\n","[I 2024-03-28 19:24:50,251] Trial 9 finished with value: 0.693739652633667 and parameters: {'hidden_dim': 64, 'dropout': 0.12263367504610267, 'num_layers': 3, 'bidirectional': True, 'batch_size': 16, 'learning_rate': 0.00011174720971737763, 'gammar': 0.0012613747085176146}. Best is trial 3 with value: 0.4764207899570465.\n","[I 2024-03-28 19:26:02,307] Trial 10 finished with value: 0.6699575781822205 and parameters: {'hidden_dim': 128, 'dropout': 0.48440553856556967, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.04871909476397721, 'gammar': 0.004167561639910392}. Best is trial 3 with value: 0.4764207899570465.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.031229529152643272 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:26:32,288] Trial 11 finished with value: 0.5941561460494995 and parameters: {'hidden_dim': 256, 'dropout': 0.031229529152643272, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.0009498197927039577, 'gammar': 0.003938262669195565}. Best is trial 3 with value: 0.4764207899570465.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4936546352688637 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:27:23,569] Trial 12 finished with value: 0.5461567044258118 and parameters: {'hidden_dim': 256, 'dropout': 0.4936546352688637, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0008041166296494402, 'gammar': 0.00335705440887519}. Best is trial 3 with value: 0.4764207899570465.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4920645212112059 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:27:59,365] Trial 13 finished with value: 0.47044864296913147 and parameters: {'hidden_dim': 256, 'dropout': 0.4920645212112059, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0005392143607908005, 'gammar': 0.0026295008166353183}. Best is trial 13 with value: 0.47044864296913147.\n","[I 2024-03-28 19:29:29,632] Trial 14 finished with value: 0.5821791291236877 and parameters: {'hidden_dim': 256, 'dropout': 0.3946462322843522, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00030356026808312533, 'gammar': 0.008570149283561547}. Best is trial 13 with value: 0.47044864296913147.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40934921363817667 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:30:39,957] Trial 15 finished with value: 0.33568206429481506 and parameters: {'hidden_dim': 256, 'dropout': 0.40934921363817667, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00413446354929088, 'gammar': 0.015636526910698563}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:31:53,314] Trial 16 finished with value: 0.472525954246521 and parameters: {'hidden_dim': 128, 'dropout': 0.38407947481424687, 'num_layers': 3, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0052174288151307984, 'gammar': 0.01963684748538851}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:33:59,300] Trial 17 finished with value: 0.43201813101768494 and parameters: {'hidden_dim': 256, 'dropout': 0.3165692749561404, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.032826001247631666, 'gammar': 0.016337680063476426}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:35:30,544] Trial 18 finished with value: 0.680682897567749 and parameters: {'hidden_dim': 256, 'dropout': 0.29277754841770703, 'num_layers': 2, 'bidirectional': True, 'batch_size': 16, 'learning_rate': 0.06555079996726318, 'gammar': 0.015771719517398836}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:36:21,674] Trial 19 finished with value: 0.649237871170044 and parameters: {'hidden_dim': 256, 'dropout': 0.42847863001890096, 'num_layers': 2, 'bidirectional': False, 'batch_size': 8, 'learning_rate': 0.02075143339886496, 'gammar': 0.0166199171398835}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:37:39,517] Trial 20 finished with value: 0.4942028522491455 and parameters: {'hidden_dim': 128, 'dropout': 0.3108564815326962, 'num_layers': 3, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0029698109712848384, 'gammar': 0.03626009129095566}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37115450166712244 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:38:32,051] Trial 21 finished with value: 0.46895095705986023 and parameters: {'hidden_dim': 256, 'dropout': 0.37115450166712244, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.019627800390717536, 'gammar': 0.0067837764314410956}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3596192128174119 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:39:26,674] Trial 22 finished with value: 0.38527342677116394 and parameters: {'hidden_dim': 256, 'dropout': 0.3596192128174119, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.021345259506421688, 'gammar': 0.006275621010146785}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:41:08,868] Trial 23 finished with value: 0.48534929752349854 and parameters: {'hidden_dim': 256, 'dropout': 0.3318881072792477, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.01921405148061912, 'gammar': 0.012825820786447761}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4354631448209203 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:42:57,962] Trial 24 finished with value: 0.556734025478363 and parameters: {'hidden_dim': 256, 'dropout': 0.4354631448209203, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.09490384210099001, 'gammar': 0.005504957533268853}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:44:35,569] Trial 25 finished with value: 0.4394259750843048 and parameters: {'hidden_dim': 256, 'dropout': 0.2771663144348726, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.002495182478336887, 'gammar': 0.011596393553943103}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3599575833821196 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:46:31,915] Trial 26 finished with value: 0.4741782248020172 and parameters: {'hidden_dim': 256, 'dropout': 0.3599575833821196, 'num_layers': 1, 'bidirectional': True, 'batch_size': 2, 'learning_rate': 0.036354025828027096, 'gammar': 0.026442257642637232}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4120661654018976 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:46:49,880] Trial 27 finished with value: 0.6843507289886475 and parameters: {'hidden_dim': 256, 'dropout': 0.4120661654018976, 'num_layers': 1, 'bidirectional': False, 'batch_size': 16, 'learning_rate': 0.011295181588316737, 'gammar': 0.05772510876431661}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:47:48,565] Trial 28 finished with value: 0.4927654564380646 and parameters: {'hidden_dim': 128, 'dropout': 0.3279680914235032, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0032088089053449935, 'gammar': 0.023002143202168267}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:50:05,782] Trial 29 finished with value: 0.6662660241127014 and parameters: {'hidden_dim': 256, 'dropout': 0.440104254014959, 'num_layers': 2, 'bidirectional': True, 'batch_size': 8, 'learning_rate': 0.038912128125232065, 'gammar': 0.00622591619213294}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:51:12,469] Trial 30 finished with value: 0.6884180307388306 and parameters: {'hidden_dim': 256, 'dropout': 0.3590901194920971, 'num_layers': 3, 'bidirectional': False, 'batch_size': 16, 'learning_rate': 0.011242348313745291, 'gammar': 0.010650734722589737}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:52:46,309] Trial 31 finished with value: 0.48328667879104614 and parameters: {'hidden_dim': 256, 'dropout': 0.26475893442533927, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00303110003573937, 'gammar': 0.01108946833470608}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:54:19,967] Trial 32 finished with value: 0.49974682927131653 and parameters: {'hidden_dim': 256, 'dropout': 0.28624950002065874, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0019321828612952094, 'gammar': 0.014557764992343535}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 19:56:07,371] Trial 33 finished with value: 0.4625539779663086 and parameters: {'hidden_dim': 256, 'dropout': 0.2997662161605292, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.005154013108140193, 'gammar': 0.02607395166816456}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18054760656702268 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:57:02,241] Trial 34 finished with value: 0.433257520198822 and parameters: {'hidden_dim': 256, 'dropout': 0.18054760656702268, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0016096698442383758, 'gammar': 0.010531661580783273}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19238509942893653 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:57:52,668] Trial 35 finished with value: 0.4741930365562439 and parameters: {'hidden_dim': 256, 'dropout': 0.19238509942893653, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00143700576783491, 'gammar': 0.007667241432358189}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.06852518387063439 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:58:05,341] Trial 36 finished with value: 0.7050883769989014 and parameters: {'hidden_dim': 64, 'dropout': 0.06852518387063439, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 2.9319251874529996e-05, 'gammar': 0.005179914330540798}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23607621275033402 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:58:57,192] Trial 37 finished with value: 0.38726454973220825 and parameters: {'hidden_dim': 256, 'dropout': 0.23607621275033402, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.026419236560917533, 'gammar': 0.05289470783548884}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22438505646984871 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:59:23,513] Trial 38 finished with value: 0.3722294270992279 and parameters: {'hidden_dim': 64, 'dropout': 0.22438505646984871, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.03068855842602363, 'gammar': 0.053439065797876634}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24507924651555968 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 19:59:44,316] Trial 39 finished with value: 0.598573625087738 and parameters: {'hidden_dim': 64, 'dropout': 0.24507924651555968, 'num_layers': 1, 'bidirectional': True, 'batch_size': 8, 'learning_rate': 0.01248137959049589, 'gammar': 0.09954916126759851}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1505657543759793 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:00:03,425] Trial 40 finished with value: 0.6263645887374878 and parameters: {'hidden_dim': 64, 'dropout': 0.1505657543759793, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.08593933217978879, 'gammar': 0.05635721323799271}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2170556630554192 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:00:32,494] Trial 41 finished with value: 0.4056592881679535 and parameters: {'hidden_dim': 64, 'dropout': 0.2170556630554192, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.030372178558782863, 'gammar': 0.05097161269286909}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21463284278231143 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:01:02,547] Trial 42 finished with value: 0.45478326082229614 and parameters: {'hidden_dim': 64, 'dropout': 0.21463284278231143, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.026066705970030055, 'gammar': 0.06100411893365963}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2342411567385491 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:01:32,733] Trial 43 finished with value: 0.5185431838035583 and parameters: {'hidden_dim': 64, 'dropout': 0.2342411567385491, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.04800222431836142, 'gammar': 0.04597329985081027}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.15798111187029754 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:01:51,862] Trial 44 finished with value: 0.3471868932247162 and parameters: {'hidden_dim': 64, 'dropout': 0.15798111187029754, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0070375503462747555, 'gammar': 0.07997722975737358}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1285426821514103 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:02:07,876] Trial 45 finished with value: 0.4651920795440674 and parameters: {'hidden_dim': 64, 'dropout': 0.1285426821514103, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.005360925042877853, 'gammar': 0.0840901464407058}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 20:03:37,718] Trial 46 finished with value: 0.5148683786392212 and parameters: {'hidden_dim': 64, 'dropout': 0.17539014097958308, 'num_layers': 4, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.008096202670790219, 'gammar': 0.07972925673690676}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.46636990507074655 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:03:52,522] Trial 47 finished with value: 0.6476293802261353 and parameters: {'hidden_dim': 64, 'dropout': 0.46636990507074655, 'num_layers': 1, 'bidirectional': True, 'batch_size': 16, 'learning_rate': 0.012816549314088104, 'gammar': 0.06800676440803556}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.09722838426641417 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:04:02,357] Trial 48 finished with value: 0.5793595314025879 and parameters: {'hidden_dim': 64, 'dropout': 0.09722838426641417, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.007361044447136308, 'gammar': 0.039717547332879875}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.13804236250491883 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:04:54,842] Trial 49 finished with value: 0.44616222381591797 and parameters: {'hidden_dim': 128, 'dropout': 0.13804236250491883, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.059170768957324746, 'gammar': 0.07426273154164148}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.09936241259438428 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:05:04,683] Trial 50 finished with value: 0.6538480520248413 and parameters: {'hidden_dim': 64, 'dropout': 0.09936241259438428, 'num_layers': 1, 'bidirectional': False, 'batch_size': 8, 'learning_rate': 0.016942654876905303, 'gammar': 0.02879426927124255}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20625124587404442 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:05:30,206] Trial 51 finished with value: 0.4262266457080841 and parameters: {'hidden_dim': 64, 'dropout': 0.20625124587404442, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.027201648529011965, 'gammar': 0.046250050706743595}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23415631031919906 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:05:52,863] Trial 52 finished with value: 0.466322660446167 and parameters: {'hidden_dim': 64, 'dropout': 0.23415631031919906, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00790459747898787, 'gammar': 0.05198995346700078}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17132102070241884 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:06:10,822] Trial 53 finished with value: 0.44918563961982727 and parameters: {'hidden_dim': 64, 'dropout': 0.17132102070241884, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.026930214935813098, 'gammar': 0.03172225419220593}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2521047872616927 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:06:26,978] Trial 54 finished with value: 0.39174553751945496 and parameters: {'hidden_dim': 64, 'dropout': 0.2521047872616927, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.01691240733438518, 'gammar': 0.06874318802667219}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.390855774759803 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:06:48,172] Trial 55 finished with value: 0.48019200563430786 and parameters: {'hidden_dim': 64, 'dropout': 0.390855774759803, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.004288169121406686, 'gammar': 0.0016902840250467505}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.00495201869429665 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:07:25,957] Trial 56 finished with value: 0.45885539054870605 and parameters: {'hidden_dim': 128, 'dropout': 0.00495201869429665, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.017206894280114973, 'gammar': 0.06813639601089681}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2565865372669714 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:07:58,699] Trial 57 finished with value: 0.37461405992507935 and parameters: {'hidden_dim': 64, 'dropout': 0.2565865372669714, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0507422012773889, 'gammar': 0.09744776410001978}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41070519803158395 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:11:04,355] Trial 58 finished with value: 0.5514213442802429 and parameters: {'hidden_dim': 256, 'dropout': 0.41070519803158395, 'num_layers': 1, 'bidirectional': True, 'batch_size': 2, 'learning_rate': 0.057103256236597365, 'gammar': 0.09225328246209592}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 20:12:41,216] Trial 59 finished with value: 0.6806530952453613 and parameters: {'hidden_dim': 64, 'dropout': 0.3489613068757806, 'num_layers': 4, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.08047307890955155, 'gammar': 0.03960023136868938}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20012688348726507 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:12:53,021] Trial 60 finished with value: 0.673523485660553 and parameters: {'hidden_dim': 256, 'dropout': 0.20012688348726507, 'num_layers': 1, 'bidirectional': False, 'batch_size': 16, 'learning_rate': 0.0006952292668133077, 'gammar': 0.0034244559519817845}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2612180652881002 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:13:24,358] Trial 61 finished with value: 0.43256649374961853 and parameters: {'hidden_dim': 64, 'dropout': 0.2612180652881002, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.04335203063056295, 'gammar': 0.06788293005134417}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.24704721812889405 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:13:39,720] Trial 62 finished with value: 0.49547478556632996 and parameters: {'hidden_dim': 64, 'dropout': 0.24704721812889405, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.015463887595027495, 'gammar': 0.08232893771823874}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2757510718552074 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:13:56,894] Trial 63 finished with value: 0.505734384059906 and parameters: {'hidden_dim': 64, 'dropout': 0.2757510718552074, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.021793837794378865, 'gammar': 0.097124790004891}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3141651462289634 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:14:20,374] Trial 64 finished with value: 0.478216290473938 and parameters: {'hidden_dim': 64, 'dropout': 0.3141651462289634, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.009457044281825243, 'gammar': 0.019353363070429758}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23294409455616438 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:15:31,382] Trial 65 finished with value: 0.3567003607749939 and parameters: {'hidden_dim': 256, 'dropout': 0.23294409455616438, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.006018315991886163, 'gammar': 0.044758764478456434}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16092247157216516 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:16:28,297] Trial 66 finished with value: 0.44750291109085083 and parameters: {'hidden_dim': 256, 'dropout': 0.16092247157216516, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0060968136961107346, 'gammar': 0.009042152073713863}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19002603761216108 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:16:53,171] Trial 67 finished with value: 0.6125415563583374 and parameters: {'hidden_dim': 256, 'dropout': 0.19002603761216108, 'num_layers': 1, 'bidirectional': False, 'batch_size': 8, 'learning_rate': 0.004581169200807416, 'gammar': 0.04524426816684129}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.22710393795391556 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:18:06,422] Trial 68 finished with value: 0.6176695823669434 and parameters: {'hidden_dim': 256, 'dropout': 0.22710393795391556, 'num_layers': 1, 'bidirectional': True, 'batch_size': 4, 'learning_rate': 0.003945409655981801, 'gammar': 0.03428406029737296}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 20:19:47,809] Trial 69 finished with value: 0.458065003156662 and parameters: {'hidden_dim': 256, 'dropout': 0.45751300968966957, 'num_layers': 2, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.009834801441477326, 'gammar': 0.005077523529059806}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.29512722784827505 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:21:30,835] Trial 70 finished with value: 0.43784499168395996 and parameters: {'hidden_dim': 256, 'dropout': 0.29512722784827505, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0338089728365869, 'gammar': 0.061173977030081886}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.27185567957423823 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:22:39,538] Trial 71 finished with value: 0.38758888840675354 and parameters: {'hidden_dim': 256, 'dropout': 0.27185567957423823, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.013566071931615315, 'gammar': 0.07431683120959127}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.27093658940688126 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:23:24,246] Trial 72 finished with value: 0.5072032809257507 and parameters: {'hidden_dim': 256, 'dropout': 0.27093658940688126, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.02223661246091033, 'gammar': 0.07882300141752364}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33085797896498437 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:24:31,565] Trial 73 finished with value: 0.41069361567497253 and parameters: {'hidden_dim': 256, 'dropout': 0.33085797896498437, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.014278935768721693, 'gammar': 0.05105867777619388}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2406662952335553 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:25:24,226] Trial 74 finished with value: 0.46234026551246643 and parameters: {'hidden_dim': 256, 'dropout': 0.2406662952335553, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0021665606638392285, 'gammar': 0.08902030114470756}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.21863003039037765 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:27:07,393] Trial 75 finished with value: 0.7427098155021667 and parameters: {'hidden_dim': 256, 'dropout': 0.21863003039037765, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.06865229154207719, 'gammar': 0.00686913698508508}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.28047494392702843 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:28:46,211] Trial 76 finished with value: 0.47417283058166504 and parameters: {'hidden_dim': 256, 'dropout': 0.28047494392702843, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.03966812608754293, 'gammar': 0.05890705648102379}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 20:28:59,791] Trial 77 finished with value: 0.6950200796127319 and parameters: {'hidden_dim': 128, 'dropout': 0.30565610955144307, 'num_layers': 2, 'bidirectional': False, 'batch_size': 16, 'learning_rate': 0.006219016172174974, 'gammar': 0.004459231446552585}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.36355364659340383 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:29:37,852] Trial 78 finished with value: 0.48353949189186096 and parameters: {'hidden_dim': 256, 'dropout': 0.36355364659340383, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0010888708922012465, 'gammar': 0.02115405298073073}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25433094364241615 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:30:20,901] Trial 79 finished with value: 0.4728505313396454 and parameters: {'hidden_dim': 256, 'dropout': 0.25433094364241615, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00031715201673334503, 'gammar': 0.04164412606211641}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.41328540199278385 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:31:09,269] Trial 80 finished with value: 0.6827269792556763 and parameters: {'hidden_dim': 256, 'dropout': 0.41328540199278385, 'num_layers': 1, 'bidirectional': True, 'batch_size': 8, 'learning_rate': 0.0036464011529129146, 'gammar': 0.07496076869963947}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2587620683217109 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:31:33,707] Trial 81 finished with value: 0.3469387888908386 and parameters: {'hidden_dim': 64, 'dropout': 0.2587620683217109, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.010564278298234918, 'gammar': 0.06629153607176266}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2231388935880303 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:31:54,999] Trial 82 finished with value: 0.6687690019607544 and parameters: {'hidden_dim': 64, 'dropout': 0.2231388935880303, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 3.5457762885059936e-05, 'gammar': 0.054459091986118584}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.37499389104749903 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:32:19,910] Trial 83 finished with value: 0.4655652344226837 and parameters: {'hidden_dim': 64, 'dropout': 0.37499389104749903, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.009456888391744765, 'gammar': 0.07101423831827924}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2650424841930087 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:32:55,040] Trial 84 finished with value: 0.3635624647140503 and parameters: {'hidden_dim': 256, 'dropout': 0.2650424841930087, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.0127094908823276, 'gammar': 0.06152397294910044}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3419620709563081 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:33:21,936] Trial 85 finished with value: 0.40585970878601074 and parameters: {'hidden_dim': 64, 'dropout': 0.3419620709563081, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.02232223209760492, 'gammar': 0.06190916267563426}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.19765949615767442 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:33:41,375] Trial 86 finished with value: 0.539329469203949 and parameters: {'hidden_dim': 128, 'dropout': 0.19765949615767442, 'num_layers': 1, 'bidirectional': False, 'batch_size': 4, 'learning_rate': 0.0064841616070062695, 'gammar': 0.04655040181914217}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23156736777847586 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:34:30,843] Trial 87 finished with value: 0.39806050062179565 and parameters: {'hidden_dim': 256, 'dropout': 0.23156736777847586, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.010334677148084432, 'gammar': 0.0294770169077901}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3220355033176155 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:34:54,850] Trial 88 finished with value: 0.4336426258087158 and parameters: {'hidden_dim': 64, 'dropout': 0.3220355033176155, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.05269561454644894, 'gammar': 0.033911132911812296}. Best is trial 15 with value: 0.33568206429481506.\n","[I 2024-03-28 20:37:21,101] Trial 89 finished with value: 0.43360257148742676 and parameters: {'hidden_dim': 256, 'dropout': 0.28724550937177185, 'num_layers': 3, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.033014931197642546, 'gammar': 0.00229517263230324}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.18543875175330202 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:37:40,783] Trial 90 finished with value: 0.4402208626270294 and parameters: {'hidden_dim': 64, 'dropout': 0.18543875175330202, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.002684827999913101, 'gammar': 0.01240372776847767}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.26863690495676956 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:38:39,905] Trial 91 finished with value: 0.4162493050098419 and parameters: {'hidden_dim': 256, 'dropout': 0.26863690495676956, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.012923589678666506, 'gammar': 0.08697525570060806}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.257202686939273 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:39:18,626] Trial 92 finished with value: 0.47555503249168396 and parameters: {'hidden_dim': 256, 'dropout': 0.257202686939273, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.02423648546804008, 'gammar': 0.06533564175816349}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2440946860621279 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:40:11,930] Trial 93 finished with value: 0.4162558615207672 and parameters: {'hidden_dim': 256, 'dropout': 0.2440946860621279, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.008219365865005709, 'gammar': 0.05413641205769756}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.20750477190452848 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:41:13,158] Trial 94 finished with value: 0.4275425970554352 and parameters: {'hidden_dim': 256, 'dropout': 0.20750477190452848, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.014125071663454964, 'gammar': 0.07927874287235873}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10629291568389501 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:42:28,073] Trial 95 finished with value: 0.47597411274909973 and parameters: {'hidden_dim': 256, 'dropout': 0.10629291568389501, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.01877090597419208, 'gammar': 0.042456412118134154}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3005729889046728 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:42:49,875] Trial 96 finished with value: 0.6675661206245422 and parameters: {'hidden_dim': 256, 'dropout': 0.3005729889046728, 'num_layers': 1, 'bidirectional': False, 'batch_size': 16, 'learning_rate': 0.01121545807164976, 'gammar': 0.09705051320745463}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.16440955299491683 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:43:02,425] Trial 97 finished with value: 0.5192833542823792 and parameters: {'hidden_dim': 64, 'dropout': 0.16440955299491683, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.027189095145991545, 'gammar': 0.048242690728414986}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2659289309990672 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:44:25,562] Trial 98 finished with value: 0.40250420570373535 and parameters: {'hidden_dim': 256, 'dropout': 0.2659289309990672, 'num_layers': 1, 'bidirectional': True, 'batch_size': 2, 'learning_rate': 0.0071887450530065435, 'gammar': 0.009435346724908002}. Best is trial 15 with value: 0.33568206429481506.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1490119719283219 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n","[I 2024-03-28 20:44:50,773] Trial 99 finished with value: 0.49048367142677307 and parameters: {'hidden_dim': 64, 'dropout': 0.1490119719283219, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.03769134925981622, 'gammar': 0.037667028101789}. Best is trial 15 with value: 0.33568206429481506.\n"]},{"output_type":"stream","name":"stdout","text":["Best Parameters: {'hidden_dim': 256, 'dropout': 0.40934921363817667, 'num_layers': 1, 'bidirectional': False, 'batch_size': 2, 'learning_rate': 0.00413446354929088, 'gammar': 0.015636526910698563}\n","Best Value: 0.33568206429481506\n"]}]},{"cell_type":"code","source":["\n","tiger = Tiger(data, labels,None,256,0.40934921363817667,1,False,2, 0.00413446354929088,0.015636526910698563)\n","\n","print(tiger.train(earlystop_train = True))\n","print(tiger.test())\n","tiger.predict(\"I love this\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"-L2Zph1lRaIR","executionInfo":{"status":"ok","timestamp":1711659273307,"user_tz":-420,"elapsed":56722,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"9d4ebdd3-a5e4-4f77-9953-dfebce2cd6fd"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40934921363817667 and num_layers=1\n","  warnings.warn(\"dropout option adds dropout after all but last \"\n"]},{"output_type":"stream","name":"stdout","text":["([tensor(0.5508), tensor(0.4295), tensor(0.4132), tensor(0.4067), tensor(0.4330), tensor(0.4195), tensor(0.4135), tensor(0.4103), tensor(0.4130)], [tensor(0.4217), tensor(0.4084), tensor(0.4082), tensor(0.4082), tensor(0.4082), tensor(0.4082), tensor(0.4082), tensor(0.4082), tensor(0.4082)], [0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81, 0.81])\n","0.7373737373737373\n"]},{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","train_loss ,val_loss,_ =  tiger.train(earlystop_train = True)\n","\n","epochs = range(1, len(train_loss) + 1)\n","\n","plt.plot(epochs, train_loss, 'b', label='Train Loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n","plt.title('Train Loss vs Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"mheQQyzsy1gx","executionInfo":{"status":"ok","timestamp":1711659680590,"user_tz":-420,"elapsed":47083,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"adcf52bf-91b1-4e19-cf05-f8e5a3f331ce"},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["prepare = PrepareData(data, labels)\n","train_loader, validation_loader, test_loader = prepare.getData(4)\n","\n","import pickle\n","\n","path_train_loader = '/content/drive/My Drive/data_mining_project/train_loader.pkl'\n","path_validation_loader = '/content/drive/My Drive/data_mining_project/validation_loader.pkl'\n","path_test_loader = '/content/drive/My Drive/data_mining_project/test_loader.pkl'\n","\n","with open(path_train_loader, 'wb') as f:\n","    pickle.dump(train_loader, f)\n","\n","with open(path_validation_loader, 'wb') as f:\n","  pickle.dump(validation_loader, f)\n","\n","with open(path_test_loader, 'wb') as f:\n","  pickle.dump(test_loader, f)"],"metadata":{"id":"f65NAg2r4VZu","executionInfo":{"status":"ok","timestamp":1711660943284,"user_tz":-420,"elapsed":812,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["\n","with open(path_train_loader, 'rb') as f:\n","    manhdataloader = pickle.load(f)\n","\n","new_dataloader = torch.utils.data.DataLoader(\n","    manhdataloader.dataset, batch_size=10)\n","new_dataloader.batch_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ui727a4n65dC","executionInfo":{"status":"ok","timestamp":1711661168899,"user_tz":-420,"elapsed":1379,"user":{"displayName":"22022521 Nguyễn Văn Mạnh","userId":"06218132299504274831"}},"outputId":"ca19ca4c-ad23-4dff-e196-62d245aa8a6b"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":[],"metadata":{"id":"TRcJwOfB7qFE"},"execution_count":null,"outputs":[]}]}